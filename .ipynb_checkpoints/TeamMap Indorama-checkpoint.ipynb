{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre requisitos:\n",
    "Tabela com colunas: nome do colaborador, data da avaliação de proficiência(primeira avaliação), nível na avaliação de proficiência, data da última avaliação, nível na última avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes dos arquivos\n",
    "NOME_TABELA_PRE = './indorama.xlsx'\n",
    "NOME_TABELA_INICIAL = './indorama_inter.xlsx'\n",
    "NOME_TABELA_TRANSFORMADA = \"./indorama_transformed.xlsx\"\n",
    "\n",
    "# Nomes das colunas\n",
    "NOME_COLUNA_NOME = 'usuario'\n",
    "NOME_COLUNA_IDIOMA = 'Curso'\n",
    "NOME_COLUNA_NIVEL_AVALIACAO = 'classificacao__ultimo_test'\n",
    "NOME_COLUNA_NIVEL_PROFICIENCIA = 'classificacao_test_0'\n",
    "NOME_COLUNA_DATA_AVALIACAO = 'data_ultimo_test'\n",
    "NOME_COLUNA_DATA_PROFICIENCIA = 'data_test_0'\n",
    "NOME_COLUNA_META_FINAL = 'Meta Final'\n",
    "NOME_COLUNA_PRAZO_META = 'Prazo Meta final'\n",
    "NOME_COLUNA_STATUS = 'Status'\n",
    "\n",
    "# Valores de filtro\n",
    "NOME_STATUS_ATIVO_FILTRO = 'Subsídio ativo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pessoal/Documentos/gitc/jupyter-graphs-angela/myenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./myenv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./myenv/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: openpyxl in ./myenv/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in ./myenv/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: streamlit in ./myenv/lib/python3.12/site-packages (1.40.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (5.4.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in ./myenv/lib/python3.12/site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in ./myenv/lib/python3.12/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in ./myenv/lib/python3.12/site-packages (from streamlit) (5.28.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (18.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./myenv/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./myenv/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in ./myenv/lib/python3.12/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./myenv/lib/python3.12/site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./myenv/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./myenv/lib/python3.12/site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in ./myenv/lib/python3.12/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./myenv/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.5.2 in ./myenv/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (1.14.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./myenv/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./myenv/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./myenv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./myenv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./myenv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./myenv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./myenv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./myenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: plotly in ./myenv/lib/python3.12/site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./myenv/lib/python3.12/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.12/site-packages (from plotly) (24.2)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.12/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in ./myenv/lib/python3.12/site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./myenv/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#requirement.txt\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install streamlit\n",
    "!pip install plotly\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import streamlit\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Table transformer\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import PatternFill, Alignment, Border, Side, Font\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes = [\n",
    "    \"Adriana Gomes Silva\",\n",
    "    \"Adriano Frugieri De Oliveira\",\n",
    "    \"Aline Da Silva Chelan\",\n",
    "    \"Carlos Afonso De Amorim\",\n",
    "    \"Cleber Barbosa Da Silva\",\n",
    "    \"Eduardo Osti Marinho De Moura\",\n",
    "    \"Fabiana Braz Da Silva\",\n",
    "    \"Fagner Virgens Silva\",\n",
    "    \"Gildson Rocha Santos\",\n",
    "    \"Gizeli Silva\",\n",
    "    \"Ismael Pereira De Jezus\",\n",
    "    \"Janete Rodrigues Pereira Da Silva\",\n",
    "    \"Jeferson Marques Goncalves\",\n",
    "    \"Juliana Siqueira Da Cruz\",\n",
    "    \"Lais De Freitas Fernandes Benvenga\",\n",
    "    \"Leonardo Barreto Da Silva\",\n",
    "    \"Luciana Cristina Anselmo\",\n",
    "    \"Luiz Henrique De Souza\",\n",
    "    \"Marcelo Alves Dos Reis\",\n",
    "    \"Marcos Roberto Pedro\",\n",
    "    \"Mayara Aparecida Rocha Garcia\",\n",
    "    \"Paulo Augusto Batista Junior\",\n",
    "    \"Priscila Nolberto Fernandes De Alencar\",\n",
    "    \"Priscilla Fernandes Yamaguchi\",\n",
    "    \"Rafael Tezolin Ribeiro Da Silva\",\n",
    "    \"Raquel Ferreira Burato\",\n",
    "    \"Roberta Nunes Maximo\",\n",
    "    \"Rodrigo Assman\",\n",
    "    \"Ronaldo Marui\",\n",
    "    \"Saulo Andrade De Oliveira\",\n",
    "    \"Thamyris Do Nascimento Gabriel\",\n",
    "    \"Vanessa Souto Breder\",\n",
    "    \"Washington Leao Machado\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nova tabela criada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_excel(NOME_TABELA_PRE) \n",
    "# Converter a coluna 'data_conclusao_do_teste' para o tipo datetime\n",
    "df['data_conclusao_do_teste'] = pd.to_datetime(df['data_conclusao_do_teste'])\n",
    "\n",
    "# Ordenar o DataFrame por 'usuario' e 'data_conclusao_do_teste'\n",
    "df = df.sort_values(by=['usuario', 'data_conclusao_do_teste'])\n",
    "\n",
    "# Criar uma lista para armazenar os novos registros\n",
    "novos_registros = []\n",
    "\n",
    "# Agrupar o DataFrame por 'usuario'\n",
    "grupos_usuario = df.groupby('usuario')\n",
    "data_atual = datetime.now()\n",
    "\n",
    "# Iterar sobre cada grupo de usuário\n",
    "for usuario, grupo_usuario in grupos_usuario:\n",
    "    if usuario not in nomes:\n",
    "        continue\n",
    "    # Dentro de cada usuário, agrupar por 'idioma'\n",
    "    grupos_idioma = grupo_usuario.groupby('natureza')\n",
    "    \n",
    "    for idioma, grupo_idioma in grupos_idioma:\n",
    "        grupo_idioma = grupo_idioma.reset_index(drop=True)\n",
    "        \n",
    "        # Criar um novo registro para cada combinação de usuário e idioma\n",
    "        novo_registro = {\n",
    "            NOME_COLUNA_NOME: usuario,\n",
    "            NOME_COLUNA_META_FINAL: grupo_idioma.iloc[-1]['meta_estabelecida'],  # Meta da última prova\n",
    "            NOME_COLUNA_PRAZO_META: grupo_idioma.iloc[-1]['prazo_meta_estabelecida'],  # Prazo da última prova\n",
    "            NOME_COLUNA_IDIOMA: idioma,  # Idioma específico\n",
    "            NOME_COLUNA_NIVEL_AVALIACAO: grupo_idioma.iloc[-1]['classificacao'],\n",
    "            NOME_COLUNA_DATA_AVALIACAO: grupo_idioma.iloc[-1]['data_conclusao_do_teste'],\n",
    "        }\n",
    "        \n",
    "        # Encontrar o índice onde 'objetivo_do_teste' é 'Avaliação de proficiência'\n",
    "        x = 0\n",
    "        i = -1\n",
    "        for gp in grupo_idioma.iloc:\n",
    "            i += 1\n",
    "            if gp['objetivo_do_teste'] == 'Avaliação de proficiência':\n",
    "                x = i\n",
    "            \n",
    "        \n",
    "        # Adicionar as datas e classificações dos testes a partir do índice x\n",
    "        for i, gp in grupo_idioma.iloc[x:].iterrows():\n",
    "            novo_registro[f\"data_test_{i}\"] = gp['data_conclusao_do_teste']\n",
    "            novo_registro[f\"classificacao_test_{i}\"] = gp['classificacao']\n",
    "        \n",
    "        # Adicionar o novo registro à lista\n",
    "        novos_registros.append(novo_registro)\n",
    "\n",
    "# Criar um novo DataFrame com os novos registros\n",
    "nova_tabela = pd.DataFrame(novos_registros)\n",
    "\n",
    "# Opcional: salvar a nova tabela em um arquivo Excel\n",
    "nova_tabela.to_excel(NOME_TABELA_INICIAL, index=False)\n",
    "\n",
    "print(\"Nova tabela criada com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classificacao_test_0', 'classificacao_test_1', 'classificacao_test_2']\n",
      "['data_test_0', 'data_test_1', 'data_test_2']\n",
      "Meta_final: B2.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: B1.2\n",
      "Prazo_meta: 2026-01-01 00:00:00\n",
      "Meta_final: B1.1\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: A1.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: B2.1\n",
      "Prazo_meta: 2025-07-01 00:00:00\n",
      "Meta_final: A2.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: A1.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: A1.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: B2+.1\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: A2.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: B2.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: B2.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: A2.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: B2+.1\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Meta_final: B1.2\n",
      "Prazo_meta: 2024-12-01 00:00:00\n",
      "Tabela salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from openpyxl.styles import PatternFill, Alignment, Border, Side, Font\n",
    "\n",
    "# Carregar os dados do arquivo\n",
    "data = pd.read_excel(NOME_TABELA_INICIAL)\n",
    "\n",
    "# Identificar todas as colunas de classificação e data\n",
    "classification_columns = [col for col in data.columns if 'classificacao_test_' in col]\n",
    "date_columns = [col for col in data.columns if 'data_test_' in col]\n",
    "\n",
    "# Garantir que as colunas estejam ordenadas corretamente\n",
    "classification_columns.sort(key=lambda x: int(x.split('_')[-1]))\n",
    "date_columns.sort(key=lambda x: int(x.split('_')[-1]))\n",
    "\n",
    "print(classification_columns)\n",
    "print(date_columns)\n",
    "\n",
    "# Verificar e substituir 'Ground zero' por 'Marco zero' nas colunas de classificações\n",
    "for col in classification_columns:\n",
    "    data[col] = data[col].replace('Ground zero', 'Marco zero')\n",
    "    data[col] = data[col].replace('Marco cero', 'Marco zero')\n",
    "\n",
    "# Ordenar os dados pelo nome do colaborador\n",
    "if NOME_COLUNA_NOME in data.columns:\n",
    "    data = data.sort_values(by=NOME_COLUNA_NOME)\n",
    "else:\n",
    "    raise KeyError(f\"A coluna '{NOME_COLUNA_NOME}' não foi encontrada no arquivo Excel.\")\n",
    "\n",
    "# Lista de idiomas\n",
    "idiomas = data[NOME_COLUNA_IDIOMA].unique()\n",
    "tabelas_classificacoes = {}\n",
    "\n",
    "# Criar lista de classificações para cada idioma\n",
    "for idioma in idiomas:\n",
    "    classificacoes_idioma = []\n",
    "    data_filtrada_idioma = data[data[NOME_COLUNA_IDIOMA] == idioma]\n",
    "    for col in classification_columns:\n",
    "        classificacoes_idioma += data_filtrada_idioma[col].unique().tolist()\n",
    "    classificacoes_idioma += data_filtrada_idioma[NOME_COLUNA_META_FINAL].unique().tolist()\n",
    "    # Remover duplicatas e valores nulos\n",
    "    classificacoes_idioma = [x for x in set(classificacoes_idioma) if pd.notna(x) and x != \"\"]\n",
    "    tabelas_classificacoes[idioma] = classificacoes_idioma\n",
    "\n",
    "# Função para ordenar as classificações\n",
    "def ordenar_classificacoes(classificacoes):\n",
    "    def classificacao_key(nivel):\n",
    "        if isinstance(nivel, str) and (nivel.lower() == 'marco zero' or nivel.lower() == 'sem definição' or nivel.lower() == 'n/a'):\n",
    "            return (0, 0, 0)\n",
    "        elif isinstance(nivel, str):\n",
    "            if '.' not in nivel:\n",
    "                letra = nivel\n",
    "                return (ord(letra[0].upper()) - ord('A'), int(letra[1]), 0)\n",
    "            nivel_split = nivel.split('.')\n",
    "            letra = nivel_split[0]\n",
    "            plus = 0\n",
    "            if '+' in letra:\n",
    "                letra = letra[:-1]\n",
    "                plus = 0.1\n",
    "            numero = int(nivel_split[1])\n",
    "            return (ord(letra[0].upper()) - ord('A'), int(letra[1]) + plus, numero)\n",
    "        return (float('inf'), 0, 0)\n",
    "    return sorted([x for x in classificacoes if pd.notna(x) and x != \"\"], key=classificacao_key)\n",
    "\n",
    "# Função para preencher a tabela transformada\n",
    "def preencher_tabela_transformada(row, classificacoes):\n",
    "    linha_usuario = {nivel: np.nan for nivel in classificacoes}\n",
    "    # Coletar todas as classificações e datas\n",
    "    classificacoes_datas = []\n",
    "    # Adicionar classificações de testes\n",
    "    for class_col, date_col in zip(classification_columns, date_columns):\n",
    "        classificacao = row.get(class_col, None)\n",
    "        data_teste = row.get(date_col, None)\n",
    "        if pd.notna(classificacao) and pd.notna(data_teste) and classificacao in classificacoes:\n",
    "            data_teste = pd.to_datetime(data_teste).strftime('%m/%Y')\n",
    "            classificacoes_datas.append((classificacao, data_teste))            \n",
    "    # Ordenar as classificações por data\n",
    "    classificacoes_datas.sort(key=lambda x: pd.to_datetime(x[1], format='%m/%Y'))\n",
    "    # Preencher as classificações com as datas\n",
    "    for classificacao, data in classificacoes_datas:\n",
    "        linha_usuario[classificacao] = data\n",
    "    # Preencher 'Caminho Percorrido' entre as classificações\n",
    "    indices = [classificacoes.index(c) for c, d in classificacoes_datas if c in classificacoes]\n",
    "    for i in range(len(indices) - 1):\n",
    "        start = indices[i]\n",
    "        end = indices[i+1]\n",
    "        for idx in range(min(start, end)+1, max(start, end)):\n",
    "            nivel = classificacoes[idx]\n",
    "            if linha_usuario[nivel] is np.nan:\n",
    "                linha_usuario[nivel] = 'Caminho Percorrido'\n",
    "    #print(classificacao, data_teste)\n",
    "    # Adicionar meta final\n",
    "    meta_final = row.get(NOME_COLUNA_META_FINAL, None)\n",
    "    prazo_meta = row.get(NOME_COLUNA_PRAZO_META, None)\n",
    "    print(\"Meta_final:\", meta_final)\n",
    "    print(\"Prazo_meta:\", prazo_meta)\n",
    "    if pd.notna(prazo_meta):\n",
    "        prazo_meta = pd.to_datetime(prazo_meta).strftime('%m/%Y')\n",
    "    if meta_final and pd.notna(meta_final) and meta_final in classificacoes:\n",
    "        linha_usuario[meta_final] = prazo_meta\n",
    "    # Adicionar 'Caminho a Percorrer' até a meta final\n",
    "    if classificacoes_datas and meta_final and meta_final in classificacoes:\n",
    "        last_classificacao = classificacoes_datas[-1][0]\n",
    "        if last_classificacao in classificacoes:\n",
    "            start_idx = classificacoes.index(last_classificacao)\n",
    "            end_idx = classificacoes.index(meta_final)\n",
    "            for idx in range(min(start_idx, end_idx)+1, max(start_idx, end_idx)):\n",
    "                nivel = classificacoes[idx]\n",
    "                if linha_usuario[nivel] is np.nan:\n",
    "                    linha_usuario[nivel] = 'Caminho a Percorrer'\n",
    "    return pd.Series(linha_usuario)\n",
    "\n",
    "# Deletar o arquivo existente, se houver\n",
    "if os.path.exists(NOME_TABELA_TRANSFORMADA):\n",
    "    os.remove(NOME_TABELA_TRANSFORMADA)\n",
    "\n",
    "# Criar tabelas separadas por idioma e salvar em Excel\n",
    "with pd.ExcelWriter(NOME_TABELA_TRANSFORMADA, engine='openpyxl') as writer:\n",
    "    for idioma in idiomas:\n",
    "        classificacoes = ordenar_classificacoes(tabelas_classificacoes[idioma])\n",
    "        data_filtrada = data[data[NOME_COLUNA_IDIOMA] == idioma]\n",
    "        tabela_transformada = data_filtrada.apply(preencher_tabela_transformada, axis=1, classificacoes=classificacoes)\n",
    "        usuarios = data_filtrada[NOME_COLUNA_NOME]\n",
    "        tabela_transformada.index = usuarios\n",
    "        tabela_transformada.to_excel(writer, sheet_name=idioma)\n",
    "\n",
    "        # Ajustar tamanhos das células e aplicar cores\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[idioma]\n",
    "\n",
    "        # Garantir que a planilha esteja visível\n",
    "        worksheet.sheet_state = 'visible'\n",
    "\n",
    "        # Ajustar largura das colunas\n",
    "        for col in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column = col[0].column_letter  # Coluna\n",
    "            for cell in col:\n",
    "                try:\n",
    "                    if cell.value is not None:\n",
    "                        cell_length = len(str(cell.value))\n",
    "                        if cell_length > max_length:\n",
    "                            max_length = cell_length\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2)\n",
    "            worksheet.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "        # Aplicar cores ao cabeçalho e células\n",
    "        header_fill = PatternFill(start_color='1f2f36', end_color='1f2f36', fill_type='solid')\n",
    "        cell_fill = PatternFill(start_color='391e70', end_color='391e70', fill_type='solid')\n",
    "        cell_fill_meta_final = PatternFill(start_color='adc22f', end_color='adc22f', fill_type='solid')\n",
    "        cell_fill_caminho_a_percorrer = PatternFill(start_color='adc22f', end_color='adc22f', fill_type='solid')\n",
    "        header_alignment = Alignment(horizontal='center', vertical='center')\n",
    "        cell_alignment = Alignment(horizontal='center', vertical='center')\n",
    "        thin_border = Border(left=Side(style='thin'), right=Side(style='thin'),\n",
    "                             top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "        header_font = Font(color='FFFFFF')\n",
    "\n",
    "        # Colorir cabeçalho\n",
    "        for cell in worksheet[1]:\n",
    "            cell.fill = header_fill\n",
    "            cell.alignment = header_alignment\n",
    "            cell.font = header_font  # Texto branco\n",
    "            cell.border = thin_border\n",
    "\n",
    "        # Colorir primeira coluna\n",
    "        for cell in worksheet['A']:\n",
    "            if cell.row > 1:\n",
    "                cell.fill = header_fill\n",
    "                cell.font = header_font\n",
    "                cell.alignment = cell_alignment\n",
    "                cell.border = thin_border\n",
    "\n",
    "        # Colorir células preenchidas, o caminho percorrido, e aplicar bordas e alinhamento\n",
    "        for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row,\n",
    "                                       min_col=2, max_col=worksheet.max_column):\n",
    "            aux = 0\n",
    "            for cell in row:\n",
    "                if cell.value not in ['Caminho Percorrido', 'Caminho a Percorrer', \"\"]:\n",
    "                    aux += 1\n",
    "\n",
    "            aux = 0\n",
    "            for cell in row:\n",
    "                if cell.value == 'Caminho Percorrido':\n",
    "                    cell.fill = cell_fill\n",
    "                    cell.value = \"\"\n",
    "                elif cell.value == 'Caminho a Percorrer':\n",
    "                    cell.fill = cell_fill_caminho_a_percorrer\n",
    "                    cell.value = \"\"\n",
    "                    aux = 2\n",
    "                elif cell.value is not None and cell.value != \"\":\n",
    "                    cell.fill = cell_fill\n",
    "                    aux += 1\n",
    "                    if aux == 3:\n",
    "                        cell.fill = cell_fill_meta_final\n",
    "                    else:\n",
    "                        cell.font = header_font\n",
    "                    cell.border = thin_border\n",
    "                cell.alignment = cell_alignment\n",
    "\n",
    "        # Fixar primeira linha e primeira coluna\n",
    "        worksheet.freeze_panes = 'B2'\n",
    "\n",
    "print(\"Tabela salva com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usuario</th>\n",
       "      <th>Marco zero</th>\n",
       "      <th>A1.2</th>\n",
       "      <th>A2.1</th>\n",
       "      <th>A2.2</th>\n",
       "      <th>B1.1</th>\n",
       "      <th>B1.2</th>\n",
       "      <th>B2.1</th>\n",
       "      <th>B2.2</th>\n",
       "      <th>B2+.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adriana Gomes Silva</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12/2023</td>\n",
       "      <td></td>\n",
       "      <td>12/2024</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adriano Frugieri De Oliveira</td>\n",
       "      <td></td>\n",
       "      <td>12/2022</td>\n",
       "      <td></td>\n",
       "      <td>12/2023</td>\n",
       "      <td></td>\n",
       "      <td>01/2026</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aline Da Silva Chelan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12/2023</td>\n",
       "      <td></td>\n",
       "      <td>12/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gildson Rocha Santos</td>\n",
       "      <td>12/2023</td>\n",
       "      <td>12/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gizeli Silva</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>05/2024</td>\n",
       "      <td></td>\n",
       "      <td>07/2025</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        usuario Marco zero     A1.2     A2.1     A2.2  \\\n",
       "0           Adriana Gomes Silva                                         \n",
       "1  Adriano Frugieri De Oliveira             12/2022           12/2023   \n",
       "2         Aline Da Silva Chelan                      12/2023            \n",
       "3          Gildson Rocha Santos    12/2023  12/2024                     \n",
       "4                  Gizeli Silva                                         \n",
       "\n",
       "      B1.1     B1.2     B2.1     B2.2 B2+.1  \n",
       "0           12/2023           12/2024        \n",
       "1           01/2026                          \n",
       "2  12/2024                                   \n",
       "3                                            \n",
       "4  05/2024           07/2025                 "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(NOME_TABELA_TRANSFORMADA)\n",
    "df.fillna(\"\", inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TeamMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuição de pessoas por nivel de proficiência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_71.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir o renderizador para um compatível com interações\n",
    "pio.renderers.default = \"iframe\"  \n",
    "\n",
    "data_original = pd.read_excel(NOME_TABELA_INICIAL, sheet_name=0)\n",
    "# Carregar dados\n",
    "\n",
    "# Renomear a coluna para facilitar o acesso\n",
    "data_original.rename(columns={NOME_COLUNA_NIVEL_AVALIACAO: 'Proficiency'}, inplace=True)\n",
    "color_scale = [\n",
    "    \"#1f77b4\",  # Azul escuro\n",
    "    \"#337ebc\",\n",
    "    \"#4c8eb3\",\n",
    "    \"#6699aa\",\n",
    "    \"#80a0a1\",\n",
    "    \"#99a799\",\n",
    "    \"#b3ae90\",\n",
    "    \"#cca588\",\n",
    "    \"#e6b07f\",\n",
    "    \"#ffba76\",\n",
    "    \"#ffb36d\",\n",
    "    \"#ffad63\",\n",
    "    \"#ffa559\",\n",
    "    \"#ff9f4f\",\n",
    "    \"#ff9945\",\n",
    "    \"#ff933b\",\n",
    "    \"#ff8d31\",\n",
    "    \"#ff8727\",\n",
    "    \"#ff811d\",\n",
    "    \"#ff7b13\",\n",
    "    \"#ff7509\",\n",
    "    \"#ff6f00\"   # Vermelho\n",
    "]\n",
    "\n",
    "# Substituir 'Ground zero' por 'Marco zero'\n",
    "if('Proficiency' not in data_original.columns):\n",
    "    exit(0)\n",
    "\n",
    "data_original['Proficiency'] = data_original['Proficiency'].replace('Ground zero', 'Marco zero')\n",
    "data_original['Proficiency'] = data_original['Proficiency'].replace('Marco cero', 'Marco zero')\n",
    "\n",
    "# Definir a ordem dos níveis do CEFR\n",
    "niveis_cefr = [\n",
    "    \"Marco zero\", \"A1.1\", \"A1.2\", \"A2.1\", \"A2.2\", \n",
    "    \"B1.1\", \"B1.2\", \"B2.1\", \"B2.2\", \"B2+.1\", \n",
    "    \"B2+.2\", \"C1.1\", \"C1.2\", \"C1.3\", \"C2\"\n",
    "]\n",
    "\n",
    "# Contar ocorrências de cada nível do CEFR\n",
    "contagem_proficiencia = data_original['Proficiency'].value_counts().reindex(niveis_cefr, fill_value=0)\n",
    "\n",
    "# Calcular porcentagens e adicionar o símbolo %\n",
    "porcentagem_proficiencia = (contagem_proficiencia / contagem_proficiencia.sum() * 100).round(2).astype(str) + '%'\n",
    "\n",
    "# Preparar os dados para plotagem\n",
    "dados_proficiencia = pd.DataFrame({\n",
    "    \"Nível de Proficiência\": niveis_cefr,\n",
    "    \"Contagem\": contagem_proficiencia.values,\n",
    "    \"Porcentagem\": porcentagem_proficiencia.values\n",
    "})\n",
    "\n",
    "# Criar um gráfico de barras com uma escala de cores discreta, atualizando o texto para incluir as porcentagens diretamente nas barras\n",
    "fig = px.bar(\n",
    "    dados_proficiencia,\n",
    "    x=\"Nível de Proficiência\",\n",
    "    y=\"Contagem\",\n",
    "    title=\"Distribuição dos Níveis de Proficiência - Última avaliação\",\n",
    "    labels={\"Contagem\": \"Número de Pessoas\", \"Nível de Proficiência\": \"Níveis do CEFR\"},\n",
    "    text=\"Porcentagem\",  # Mostrar a porcentagem diretamente em cada barra\n",
    "    color=\"Nível de Proficiência\",  # Adicionar diferenciação de cor\n",
    "    color_discrete_sequence=color_scale  # Usar uma escala de cores qualitativa\n",
    ")\n",
    "\n",
    "# Melhorar o layout e a estética\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.update_layout(\n",
    "    xaxis=dict(categoryorder='array', categoryarray=niveis_cefr),\n",
    "    template=\"plotly_white\",  # Tema claro para maior destaque\n",
    "    title_font=dict(size=20, family='Arial, bold'),\n",
    "    xaxis_title_font=dict(size=14, family='Arial'),\n",
    "    yaxis_title_font=dict(size=14, family='Arial'),\n",
    ")\n",
    "\n",
    "# Mostrar o gráfico\n",
    "fig.show()\n",
    "fig.write_html(NOME_TABELA_INICIAL + '_barras_HTML.html', auto_open=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_72.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Ler a planilha específica\n",
    "transformed_single_language = pd.read_excel(NOME_TABELA_TRANSFORMADA, sheet_name='idioma inglês')\n",
    "\n",
    "# 2. Verificar se a coluna NOME_COLUNA_NOME existe\n",
    "if NOME_COLUNA_NOME not in transformed_single_language.columns:\n",
    "    raise KeyError(f\"A coluna '{NOME_COLUNA_NOME}' não está presente no DataFrame\")\n",
    "\n",
    "# 3. Definir as colunas CEFR relevantes\n",
    "cef_columns = ['Marco zero', 'A1.1', 'A1.2', 'A2.1', 'A2.2', \n",
    "              'B1.1', 'B1.2', 'B2.1', 'B2.2', 'B2+.1', \n",
    "              'B2+.2', 'C1.1', 'C1.2', 'C1.3']\n",
    "cef_columns = [col for col in cef_columns if col in transformed_single_language.columns]\n",
    "# 4. Selecionar apenas as colunas existentes\n",
    "transformed_single_language = transformed_single_language[\n",
    "    [NOME_COLUNA_NOME] + cef_columns\n",
    "]\n",
    "\n",
    "# 5. Extrair as colunas de colaboradores e datas\n",
    "colaboradores = transformed_single_language[[NOME_COLUNA_NOME]]\n",
    "dates = transformed_single_language[cef_columns]\n",
    "\n",
    "# 6. Converter os dados para formato longo (long format)\n",
    "long_data = pd.melt(\n",
    "    pd.concat([colaboradores, dates], axis=1),\n",
    "    id_vars=[NOME_COLUNA_NOME],\n",
    "    var_name='CEFR Level',\n",
    "    value_name='Date'\n",
    ")\n",
    "\n",
    "# 7. Remover linhas com datas NaN\n",
    "long_data = long_data.dropna(subset=['Date'])\n",
    "\n",
    "# 8. Definir a ordem dos níveis CEFR, incluindo \"Marco zero\"\n",
    "# 9. Converter 'CEFR Level' para categórico ordenado\n",
    "long_data['CEFR Level'] = pd.Categorical(\n",
    "    long_data['CEFR Level'],\n",
    "    categories=cef_columns,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# 10. Ordenar os dados pelo colaborador e pela ordem dos níveis CEFR\n",
    "long_data = long_data.sort_values(by=[NOME_COLUNA_NOME, 'CEFR Level'])\n",
    "\n",
    "# 11. Criar figura\n",
    "fig = go.Figure()\n",
    "\n",
    "# 12. Preparar um dicionário para mapear as cores dos marcadores por indivíduo\n",
    "marker_color_map = {}\n",
    "\n",
    "# 13. Adicionar linhas para cada indivíduo\n",
    "for name in long_data[NOME_COLUNA_NOME].unique():\n",
    "    individual_data = long_data[long_data[NOME_COLUNA_NOME] == name].sort_values(by='CEFR Level')\n",
    "    \n",
    "    # Definir as cores das linhas com base na lógica original\n",
    "    if len(individual_data) == 2:\n",
    "        line_segments = ['#adc22f']\n",
    "        marker_colors = ['#391e70', '#adc22f']\n",
    "    elif len(individual_data) >= 3:\n",
    "        # Ajuste para mais de 2 pontos\n",
    "        line_segments = ['#391e70'] * (len(individual_data) - 2) + ['#adc22f']\n",
    "        marker_colors = ['#391e70'] * (len(individual_data) - 1) + ['#adc22f']\n",
    "    else:\n",
    "        # Apenas um ponto\n",
    "        line_segments = []\n",
    "        marker_colors = ['#391e70']\n",
    "    \n",
    "    # Adicionar segmentos de linhas conectando apenas pontos consecutivos\n",
    "    for i in range(len(individual_data) - 1):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=individual_data['CEFR Level'].iloc[i:i+2],\n",
    "                y=[name, name],\n",
    "                mode='lines',\n",
    "                line=dict(width=2, color=line_segments[i] if i < len(line_segments) else '#391e70'),\n",
    "                showlegend=False,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Armazenar as cores dos marcadores\n",
    "    marker_color_map[name] = marker_colors\n",
    "\n",
    "# 14. Adicionar marcadores após as linhas para garantir que fiquem por cima\n",
    "for name in long_data[NOME_COLUNA_NOME].unique():\n",
    "    individual_data = long_data[long_data[NOME_COLUNA_NOME] == name].sort_values(by='CEFR Level')\n",
    "    colors = marker_color_map.get(name, ['#391e70'] * len(individual_data))\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=individual_data['CEFR Level'],\n",
    "            y=[name] * len(individual_data),\n",
    "            mode='markers',\n",
    "            marker=dict(size=8, color=colors),\n",
    "            text=individual_data['Date'],\n",
    "            hoverinfo='text',\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 15. Ordenar os membros da equipe\n",
    "team_members = sorted(long_data[NOME_COLUNA_NOME].unique())\n",
    "\n",
    "# 16. Atualizar layout da figura com a ordem correta das categorias\n",
    "fig.update_layout(\n",
    "    title='Mapa da Equipe e Linha do Tempo da Progressão dos Níveis CEFR',\n",
    "    xaxis_title='Nível CEFR',\n",
    "    yaxis_title='Membros da Equipe',\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        fixedrange=False,  # Permitir zoom e pan\n",
    "        type='category',\n",
    "        categoryorder='array',\n",
    "        categoryarray=cef_columns,  # Ordem especificada dos níveis CEFR\n",
    "        range=['Marco zero', 'C1.3'],  # Ajuste conforme necessário\n",
    "        side='top'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        automargin=True,\n",
    "        autorange='reversed',\n",
    "        fixedrange=False,  # Permitir zoom e pan\n",
    "        type='category',\n",
    "        categoryorder='array',\n",
    "        categoryarray=team_members,  # Ordem alfabética dos membros\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    height=800,\n",
    "    width=1000,\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    ")\n",
    "\n",
    "# 17. Adicionar anotações para as datas nos marcadores\n",
    "for _, row in long_data.iterrows():\n",
    "    fig.add_annotation(\n",
    "        x=row['CEFR Level'],\n",
    "        y=row[NOME_COLUNA_NOME],\n",
    "        text=row['Date'],\n",
    "        showarrow=False,\n",
    "        font=dict(size=10),\n",
    "        align='center',\n",
    "        xanchor='center',\n",
    "        yshift=-10,  # Mover texto para baixo\n",
    "        xshift=-20,  # Mover texto para a esquerda\n",
    "    )\n",
    "\n",
    "# 18. Exibir o gráfico\n",
    "fig.show()\n",
    "fig.write_html(NOME_TABELA_INICIAL + '_META_HTML.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuição de Colaboradores por Nível CEFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .output_scroll { height: auto !important; max-height: none !important; }\n",
       "    </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bc166210a74efb91d6d077151fe2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Idiomas:', options=('idioma inglês',), value='idioma inglês')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c476dbb1957341bc8de71a405df7c252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "niveis_cefr = [\n",
    "    \"Marco zero\", \"A1.1\", \"A1.2\", \"A2.1\", \"A2.2\", \n",
    "    \"B1.1\", \"B1.2\", \"B2.1\", \"B2.2\", \"B2+.1\", \n",
    "    \"B2+.2\", \"C1.1\", \"C1.2\", \"C1.3\", \"C2\"\n",
    "]\n",
    "\n",
    "# Optional: Define the order for 'Grupo Nível'\n",
    "grupo_niveis_order = ['Nível limitado', 'Nível independente', 'Nível sólido', 'Nível competente']\n",
    "\n",
    "# Step 2: Display Custom CSS (Optional)\n",
    "display(HTML(\"\"\"\n",
    "    <style>\n",
    "        .output_scroll { height: auto !important; max-height: none !important; }\n",
    "    </style>\n",
    "\"\"\"))\n",
    "# Step 4: Load the Excel File\n",
    "try:\n",
    "    df = pd.read_excel(NOME_TABELA_INICIAL)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"The file {NOME_TABELA_INICIAL} was not found. Please check the path.\")\n",
    "\n",
    "# Step 5: Rename Columns for Consistency\n",
    "df.rename(columns={\n",
    "    NOME_COLUNA_NOME: 'Colaborador',\n",
    "    NOME_COLUNA_NIVEL_PROFICIENCIA: 'Classificação'\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 6: Define the Grouping Function\n",
    "def group_level(level):\n",
    "    \"\"\"\n",
    "    Groups the CEFR levels into broader categories.\n",
    "\n",
    "    Parameters:\n",
    "    - level (str): The CEFR level of a collaborator.\n",
    "\n",
    "    Returns:\n",
    "    - str: The grouped level category.\n",
    "    \"\"\"\n",
    "    if isinstance(level, str):\n",
    "        if level.startswith('A') or level.startswith('M') or level.startswith('G'):\n",
    "            return 'Nível limitado'\n",
    "        elif level.startswith('B'):\n",
    "            if '+' in level:\n",
    "                return 'Nível sólido'\n",
    "            return 'Nível independente'\n",
    "        elif level.startswith('C'):\n",
    "            return 'Nível competente'\n",
    "    return None  # Exclude 'Outro' and any non-matching entries\n",
    "\n",
    "# Step 7: Apply the Grouping Function\n",
    "df['Grupo Nível'] = df['Classificação'].apply(group_level)\n",
    "\n",
    "# Step 8: Filter Out 'Outro' and Any Non-Matching Entries\n",
    "df_filtered = df.dropna(subset=['Grupo Nível']).copy()\n",
    "\n",
    "# Step 9: Get Unique 'Idioma' Values\n",
    "idiomas = df_filtered[NOME_COLUNA_IDIOMA].dropna().unique()\n",
    "idiomas_sorted = sorted(idiomas)  # Optional: sort the languages alphabetically\n",
    "\n",
    "# Step 10: Define the Function to Create Sunburst Chart for a Given 'Idioma'\n",
    "def create_sunburst(selected_idioma):\n",
    "    \"\"\"\n",
    "    Creates a Sunburst chart for the selected 'Idioma'.\n",
    "\n",
    "    Parameters:\n",
    "    - selected_idioma (str): The selected language.\n",
    "\n",
    "    Returns:\n",
    "    - Plotly Figure: The Sunburst chart.\n",
    "    \"\"\"\n",
    "    # Filter data for the selected 'Idioma'\n",
    "    df_idioma = df_filtered[df_filtered[NOME_COLUNA_IDIOMA] == selected_idioma].copy()\n",
    "\n",
    "    # Step 11: Count the Number of Collaborators in Each CEFR Level\n",
    "    cefr_counts = df_idioma['Classificação'].value_counts().reset_index()\n",
    "    cefr_counts.columns = ['Classificação', 'Count']\n",
    "\n",
    "    # Set 'Classificação' as a categorical variable with the specified order\n",
    "    cefr_counts['Classificação'] = pd.Categorical(\n",
    "        cefr_counts['Classificação'],\n",
    "        categories=niveis_cefr,\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    # Step 12: Assign 'Grupo Nível' to Each CEFR Level\n",
    "    cefr_counts['Grupo Nível'] = cefr_counts['Classificação'].apply(group_level)\n",
    "\n",
    "    # Set 'Grupo Nível' as a categorical variable with the specified order\n",
    "    cefr_counts['Grupo Nível'] = pd.Categorical(\n",
    "        cefr_counts['Grupo Nível'],\n",
    "        categories=grupo_niveis_order,\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    # Drop any rows where 'Grupo Nível' is NaN after categorization\n",
    "    cefr_counts.dropna(subset=['Grupo Nível'], inplace=True)\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_count = cefr_counts['Count'].sum()\n",
    "    cefr_counts['Percentage'] = (cefr_counts['Count'] / total_count) * 100\n",
    "\n",
    "    # Sort the DataFrame to respect the specified order\n",
    "    cefr_counts.sort_values(['Grupo Nível', 'Classificação'], inplace=True)\n",
    "\n",
    "    # Step 13: Create the Sunburst Chart\n",
    "    fig = px.sunburst(\n",
    "        cefr_counts,\n",
    "        path=['Grupo Nível', 'Classificação'],\n",
    "        values='Count',\n",
    "        color='Grupo Nível',\n",
    "        color_discrete_map={\n",
    "            'Nível limitado': 'lightblue',\n",
    "            'Nível independente': 'lightgreen',\n",
    "            'Nível competente': 'lightcoral',\n",
    "            'Nível sólido': 'lightgray'\n",
    "        },\n",
    "        title=f'Distribuição de Colaboradores por Nível CEFR - Idioma: {selected_idioma} - Proficiência',\n",
    "        hover_data={'Count': True, 'Percentage': ':.2f'},  # Add percentage to hover data\n",
    "        labels={'Count': 'Número de Colaboradores', 'Percentage': 'Porcentagem'}\n",
    "    )\n",
    "\n",
    "    # Step 14: Update Layout for Better Appearance\n",
    "    fig.update_layout(\n",
    "        margin=dict(t=50, l=25, r=25, b=25)\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Step 15: Create an Interactive Dropdown Widget\n",
    "idioma_dropdown = widgets.Dropdown(\n",
    "    options=idiomas_sorted,\n",
    "    value=idiomas_sorted[0] if len(idiomas_sorted) > 0 else None,  # Set the default value to the first language\n",
    "    description='Idiomas:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Step 16: Define the Function to Update the Plot Based on Dropdown Selection\n",
    "def update_plot(selected_idioma):\n",
    "    if selected_idioma is not None:\n",
    "        fig = create_sunburst(selected_idioma)\n",
    "        fig.show()\n",
    "        fig.write_html(NOME_TABELA_INICIAL + '_PIZZA_HTML.html', auto_open=True)\n",
    "    else:\n",
    "        print(\"No idioma selected.\")\n",
    "\n",
    "# Step 17: Use `interactive_output` to Link the Dropdown with the Plot Update Function\n",
    "out = widgets.interactive_output(update_plot, {'selected_idioma': idioma_dropdown})\n",
    "\n",
    "# Step 18: Display the Dropdown and the Output Plot\n",
    "display(idioma_dropdown, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .output_scroll { height: auto !important; max-height: none !important; }\n",
       "    </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4bacd9bcba4368a281edecdbfd7a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Idiomas:', options=('idioma inglês',), value='idioma inglês')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4d86fd83e24c2db122fb86b6b42c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Adjust Jupyter Notebook Output Cell Height\n",
    "display(HTML(\"\"\"\n",
    "    <style>\n",
    "        .output_scroll { height: auto !important; max-height: none !important; }\n",
    "    </style>\n",
    "\"\"\"))\n",
    "\n",
    "# Step 2: Load the Excel File\n",
    "df = pd.read_excel(NOME_TABELA_INICIAL)\n",
    "\n",
    "# Step 3: Rename Columns for Consistency\n",
    "df.rename(columns={\n",
    "    NOME_COLUNA_NOME: NOME_COLUNA_NOME,\n",
    "    NOME_COLUNA_NIVEL_AVALIACAO: 'Classificação'\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 4: Define the Grouping Function\n",
    "def group_level(level):\n",
    "    \"\"\"\n",
    "    Groups the CEFR levels into broader categories.\n",
    "\n",
    "    Parameters:\n",
    "    - level (str): The CEFR level of a collaborator.\n",
    "\n",
    "    Returns:\n",
    "    - str: The grouped level category.\n",
    "    \"\"\"\n",
    "    if isinstance(level, str):\n",
    "        if level.startswith('A') or level.startswith('M') or level.startswith('G'):\n",
    "            return 'Nível limitado'\n",
    "        elif level.startswith('B'):\n",
    "            if '+' in level:\n",
    "                return 'Nível sólido'\n",
    "            return 'Nível independente'\n",
    "        elif level.startswith('C'):\n",
    "            return 'Nível competente'\n",
    "    return None  # Exclude 'Outro' and any non-matching entries\n",
    "\n",
    "# Step 5: Apply the Grouping Function\n",
    "df['Grupo Nível'] = df['Classificação'].apply(group_level)\n",
    "\n",
    "# Step 6: Filter Out 'Outro' and Any Non-Matching Entries\n",
    "df_filtered = df.dropna(subset=['Grupo Nível']).copy()\n",
    "\n",
    "# Step 7: Get Unique 'Idioma' Values\n",
    "idiomas = df_filtered[NOME_COLUNA_IDIOMA].dropna().unique()\n",
    "idiomas_sorted = sorted(idiomas)  # Optional: sort the languages alphabetically\n",
    "\n",
    "# Step 8: Define the Function to Create Sunburst Chart for a Given 'Idioma'\n",
    "def create_sunburst(selected_idioma):\n",
    "    \"\"\"\n",
    "    Creates a Sunburst chart for the selected 'Idioma'.\n",
    "\n",
    "    Parameters:\n",
    "    - selected_idioma (str): The selected language.\n",
    "\n",
    "    Returns:\n",
    "    - Plotly Figure: The Sunburst chart.\n",
    "    \"\"\"\n",
    "    # Filter data for the selected 'Idioma'\n",
    "    df_idioma = df_filtered[df_filtered[NOME_COLUNA_IDIOMA] == selected_idioma].copy()\n",
    "\n",
    "    # Step 9: Count the Number of Collaborators in Each CEFR Level\n",
    "    cefr_counts = df_idioma['Classificação'].value_counts().reset_index()\n",
    "    cefr_counts.columns = ['Classificação', 'Count']\n",
    "\n",
    "    # Step 10: Assign 'Grupo Nível' to Each CEFR Level\n",
    "    cefr_counts['Grupo Nível'] = cefr_counts['Classificação'].apply(group_level)\n",
    "\n",
    "    # Ensure no 'Outro' is present\n",
    "    cefr_counts = cefr_counts.dropna(subset=['Grupo Nível'])\n",
    "\n",
    "    # Step 11: Create the Sunburst Chart\n",
    "    fig = px.sunburst(\n",
    "        cefr_counts,\n",
    "        path=['Grupo Nível', 'Classificação'],\n",
    "        values='Count',\n",
    "        color='Grupo Nível',\n",
    "        color_discrete_map={\n",
    "            'Nível limitado': 'lightblue',\n",
    "            'Nível independente': 'lightgreen',\n",
    "            'Nível competente': 'lightcoral',\n",
    "            'Nível sólido': 'lightgray'\n",
    "        },\n",
    "        title=f'Distribuição de Colaboradores por Nível CEFR - Idioma: {selected_idioma} - Acompanhamento',\n",
    "        hover_data={'Count': True},\n",
    "        labels={'Count': 'Número de Colaboradores'}\n",
    "    )\n",
    "\n",
    "    # Step 12: Update Layout for Better Appearance\n",
    "    fig.update_layout(\n",
    "        margin=dict(t=50, l=25, r=25, b=25)\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Step 13: Create an Interactive Dropdown Widget\n",
    "idioma_dropdown = widgets.Dropdown(\n",
    "    options=idiomas_sorted,\n",
    "    value=idiomas_sorted[0],  # Set the default value to the first language\n",
    "    description='Idiomas:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Step 14: Define the Function to Update the Plot Based on Dropdown Selection\n",
    "def update_plot(selected_idioma):\n",
    "    fig = create_sunburst(selected_idioma)\n",
    "    fig.show()\n",
    "\n",
    "# Step 15: Use `interactive_output` to Link the Dropdown with the Plot Update Function\n",
    "out = widgets.interactive_output(update_plot, {'selected_idioma': idioma_dropdown})\n",
    "\n",
    "# Step 16: Display the Dropdown and the Output Plot\n",
    "display(idioma_dropdown, out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
